{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["OKYTGkzknbme","eohdu7sP0Rwm"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Functions"],"metadata":{"id":"Q9chk3y_Kb1z"}},{"cell_type":"code","source":["!pip install tldextract #If required\n","!apt install libzbar0 #If required\n","!pip install pyzbar #If required"],"metadata":{"id":"4nw2-gatKpYv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664702994215,"user_tz":-480,"elapsed":12488,"user":{"displayName":"JS Chong","userId":"17987847510974043506"}},"outputId":"d49fdff6-fa38-4efe-a563-2e26e148dd80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tldextract in /usr/local/lib/python3.7/dist-packages (3.3.1)\n","Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract) (1.5.1)\n","Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from tldextract) (2.10)\n","Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract) (2.23.0)\n","Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from requests-file>=1.4->tldextract) (1.15.0)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","libzbar0 is already the newest version (0.10+doc-10.1build2).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyzbar in /usr/local/lib/python3.7/dist-packages (0.1.9)\n"]}]},{"cell_type":"markdown","source":["## QR Code Scanner"],"metadata":{"id":"f6TV9I20K4qH"}},{"cell_type":"code","source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","from IPython.display import Image\n","from google.colab.patches import cv2_imshow\n","import cv2\n","import numpy as np\n","from pyzbar.pyzbar import decode\n","\n","# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","def take_photo(show=0, quality=1):\n","    js = Javascript('''\n","        async function takePhoto(quality) {\n","        const div = document.createElement('div');\n","        const capture = document.createElement('button');\n","        capture.textContent = 'Capture';\n","        div.appendChild(capture);\n","\n","        const video = document.createElement('video');\n","        video.style.display = 'block';\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","        document.body.appendChild(div);\n","        div.appendChild(video);\n","        video.srcObject = stream;\n","        await video.play();\n","\n","        // Resize the output to fit the video element.\n","        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","        // Wait for Capture to be clicked.\n","        await new Promise((resolve) => capture.onclick = resolve);\n","\n","        const canvas = document.createElement('canvas');\n","        canvas.width = video.videoWidth;\n","        canvas.height = video.videoHeight;\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        stream.getVideoTracks()[0].stop();\n","        div.remove();\n","        return canvas.toDataURL('image/jpeg', quality);\n","        }\n","        ''')\n","    display(js)\n","\n","    # get photo data\n","    data = eval_js('takePhoto({})'.format(quality))\n","    # get OpenCV format image\n","    img = js_to_image(data) \n","    \n","    if show:\n","        # Get bounding box\n","        decoder = cv2.QRCodeDetector()\n","        data, points, _ = decoder.detectAndDecode(img)\n","\n","        if points is not None:\n","            points = points[0]\n","            for i in range(len(points)):\n","                pt1 = [int(val) for val in points[i]]\n","                pt2 = [int(val) for val in points[(i + 1) % 4]]\n","                cv2.line(img, pt1, pt2, color=(255, 0, 0), thickness=3)\n","\n","            cv2_imshow(img)\n","\n","    # Get website/info\n","    data = decode(img)[0].data\n","    data_str = data.decode(\"utf-8\")\n","    print('Decoded data: ', data_str)\n","    \n","    return data_str\n"],"metadata":{"id":"22vK_-nCK3Gx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Phishing Identifiers"],"metadata":{"id":"9fEhd8uJK8Da"}},{"cell_type":"markdown","source":["## Jie Sheng"],"metadata":{"id":"OKYTGkzknbme"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","import tldextract\n","import pandas as pd\n","import numpy as np\n","import re\n","from urllib.parse import urlparse\n","from nltk.util import ngrams\n","from sklearn.feature_extraction import DictVectorizer\n","from scipy.sparse import csr_matrix\n","\n","#Using IP Addresses within Address Bar\n","def isIPAddress(url):\n","    # declaring the regex pattern for IP addresses\n","    pattern = re.compile(r'(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})')\n","    if (pattern.search(url)):\n","        return 1\n","    return 0\n","\n","#Long URL (Characters)\n","def urlLength(url):\n","    return len(url)\n","\n","#URL with @ Symbol\n","def hasAt(url):\n","    if '@' in url:\n","        return 1\n","    return 0\n","\n","#URL with multiple \"//\" for redirecting\n","def hasDoubleSlash(url):\n","    if '//' in url:\n","        return 1\n","    return 0\n","\n","#URL Domain with - Symbol\n","def hasDash(url):\n","    if '-' in url.split('.')[0]:\n","        return 1\n","    return 0\n","\n","#URL with multiple \".\" for subdomains\n","def hasMultipleDots(url):\n","    if '.' in url:\n","        return 1\n","    return 0\n","\n","#URL with \"?\"\n","def hasQuestion(url):\n","    if '?' in url:\n","        return 1\n","    return 0\n","\n","#URL with \"cmd\"\n","def hasCmd(url):\n","    if 'cmd' in url:\n","        return 1\n","    return 0\n","\n","#URL with \".php\"\n","def hasPhp(url):\n","    if '.php' in url:\n","        return 1\n","    return 0\n","\n","#URL with HTTPS in domain\n","def hasHTTPorHTTPS(url):\n","    if 'http' in url:\n","        return 1\n","    return 0\n","\n","#Total Digits Domain\n","def digitsDomain(url):\n","    return len(re.sub(\"[^0-9]\", \"\", url.split(\"/\", 1)[0]))\n","\n","#Total Digits Path\n","def digitsPath(url):\n","    if len(url.split(\"/\", 1)) == 2:\n","        return len(re.sub(\"[^0-9]\", \"\", url.split(\"/\", 1)[1]))\n","    return 0\n","\n","def generate_url_ngrams(n: int, url: str):\n","    url_formated = ''\n","    \n","    for index, char in enumerate(url):\n","        if index % n == 0:\n","            url_formated += ' '\n","        url_formated += char\n","\n","    ngram = ngrams(sequence=nltk.word_tokenize(url_formated), n=n)\n","    \n","    ngram_url = {}\n","    for grams in ngram:\n","        for gx in grams:\n","            ngram_url[gx] = 1\n","    return ngram_url\n","\n","\n","def get_fields_url(url: str):\n","    try:\n","        features = dict()\n","\n","        url_tldextract = tldextract.extract(url) \n","        url_urlparse = urlparse(f\"http://{url}\")\n","        url_info = [\n","            {\"name\": \"domain\", \"string\": url_tldextract.domain},\n","            {\"name\": \"subdomain\", \"string\": url_tldextract.subdomain},\n","            {\"name\": \"suffix\", \"string\": url_tldextract.suffix},\n","            {\"name\": \"path\", \"string\": url_urlparse.path},\n","            {\"name\": \"params\", \"string\": url_urlparse.params},\n","            {\"name\": \"query\", \"string\": url_urlparse.query},\n","            {\"name\": \"fragment\", \"string\": url_urlparse.fragment}\n","        ]\n","        features.update(generate_url_ngrams(2, url_tldextract.domain))\n","        \n","        for each_url in url_info:\n","            features[f'len_{each_url[\"name\"]}'] = len(each_url[\"string\"])\n","            for char_ in list(map(str, \"-@_?=&./,\")):\n","                features[f'char{char_}-{each_url[\"name\"]}'] = each_url[\"string\"].count(char_)\n","\n","            if \"domain\" == each_url[\"name\"] or \"path\" == each_url[\"name\"]:\n","                total_letter, total_number = 0, 0\n","                for char_ in list(map(str, \"abcdefghijklmnopqrstuvwxyz\")):\n","                    total_letter += each_url[\"string\"].lower().count(char_)\n","\n","                for char_ in list(map(str, \"0123456789\")):\n","                    total_number += each_url[\"string\"].lower().count(char_)\n","\n","                features[f'letter_len_{each_url[\"name\"]}'] = total_letter\n","                features[f'number_len_{each_url[\"name\"]}'] = total_number\n","    except Exception as e:\n","        return e      \n","    return features   \n","\n","def get_features(url):\n","    if \"http://\" == url[:7]:\n","        url = url[7:]\n","    elif \"https://\" == url[:8]:\n","        url = url[8:]\n","    features_json = {}\n","    features_json = get_fields_url(url)\n","    features_json['ip_addr'] = isIPAddress(url)\n","    features_json['url_len'] = urlLength(url)\n","    features_json['has_at'] = hasAt(url)\n","    features_json['has_double_slash'] = hasDoubleSlash(url)\n","    features_json['has_dash'] = hasDash(url)\n","    features_json['has_multiple_dots'] = hasMultipleDots(url)\n","    features_json['has_question_mark'] = hasQuestion(url)\n","    features_json['has_cmd'] = hasCmd(url)\n","    features_json['has_php'] = hasPhp(url)\n","    features_json['has_http'] = hasHTTPorHTTPS(url)\n","    features_json['digits_domain'] = digitsDomain(url)\n","    features_json['digits_path'] = digitsPath(url)\n","    return features_json\n","\n","def feature_to_vector(features_json, pre_processor):   \n","    X = pre_processor.transform([features_json])\n","    X = csr_matrix(X)\n","    X = X.tocsr()\n","    return X\n","\n","def get_prediction(vector, lg, xgb, rfc, nn):\n","    #print(lg.predict(vector),xgb.predict(vector),rfc.predict(vector),nn.predict(vector))\n","    if nn.predict(vector) == 1:\n","        nn_pred = 1\n","    else:\n","        nn_pred = 0\n","    if lg.predict(vector)+xgb.predict(vector)+rfc.predict(vector)+nn_pred > 2:\n","        return 1\n","    return 0\n","\n","def url_phishing_predictor_js(url, pre_processor, lg, xgb, rfc, nn):\n","    return get_prediction(feature_to_vector(get_features(url), pre_processor), lg, xgb, rfc, nn)"],"metadata":{"id":"n3RrPntlwUyT","executionInfo":{"status":"ok","timestamp":1664718252325,"user_tz":-480,"elapsed":912,"user":{"displayName":"JS Chong","userId":"17987847510974043506"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d8b507bc-2817-4bf8-972a-1956e8e75adb"},"execution_count":125,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["## Jun Long"],"metadata":{"id":"eohdu7sP0Rwm"}},{"cell_type":"code","source":["#!pip install tld\n","import pandas as pd\n","import numpy as np\n","import re\n","from urllib.parse import urlparse\n","from tld import get_tld, is_tld\n","\n","def process_tld(url):\n","    try:\n","        res = get_tld(url, as_object = True, fail_silently=False,fix_protocol=True)\n","        pri_domain= res.parsed_url.netloc\n","    except :\n","        pri_domain= None\n","    return pri_domain\n","\n","def abnormal_url(url):\n","    hostname = urlparse(url).hostname\n","    hostname = str(hostname)\n","    match = re.search(hostname, url)\n","    if match:\n","        # print match.group()\n","        return 1\n","    else:\n","        # print 'No matching pattern found'\n","        return 0\n","\n","def httpSecure(url):\n","    htp = urlparse(url).scheme\n","    match = str(htp)\n","    if match=='https':\n","        # print match.group()\n","        return 1\n","    else:\n","        # print 'No matching pattern found'\n","        return 0\n","\n","def digit_count(url):\n","    digits = 0\n","    for i in url:\n","        if i.isnumeric():\n","            digits = digits + 1\n","    return digits\n","    \n","def letter_counter(url):\n","    letter_count = 0\n","    for i in url: \n","        if i.isalpha():\n","            letter_count += 1\n","        return letter_count    \n","\n","def Shortining_Service(url):\n","    match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n","                      'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n","                      'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n","                      'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n","                      'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n","                      'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n","                      'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n","                      'tr\\.im|link\\.zip\\.net',\n","                      url)\n","    if match:\n","        return 1\n","    else:\n","        return 0\n","\n","def having_ip_address(url):\n","    match = re.search(\n","        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n","        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n","        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n","        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4 with port\n","        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)' # IPv4 in hexadecimal\n","        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}|'\n","        '([0-9]+(?:\\.[0-9]+){3}:[0-9]+)|'\n","        '((?:(?:\\d|[01]?\\d\\d|2[0-4]\\d|25[0-5])\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d|\\d)(?:\\/\\d{1,2})?)', url)  # Ipv6\n","    if match:\n","        return 1\n","    else:\n","        return 0\n","\n","'''\n","['url', 'url_len', 'domain', '@', '?', '-', '=', '.',\n","       '#', '%', '+', '$', '!', '*', ',', '//', 'abnormal_url', 'https',\n","       'digits', 'letters', 'Shortining_Service', 'having_ip_address'],\n","\n","'''\n","def feature_to_input(link):\n","    link_df = {'url': [link]}\n","    data = pd.DataFrame(link_df)\n","    data[\"url\"] = data[\"url\"].replace(\"www\",\"\", regex=True)\n","    data['url_len'] = data['url'].apply(lambda x: len(str(x)))\n","    data['domain'] = data['url'].apply(lambda i: process_tld(i))\n","    feature = ['@','?','-','=','.','#','%','+','$','!','*',',','//']\n","    for a in feature:\n","        data[a] = data['url'].apply(lambda i: i.count(a))\n","    data['abnormal_url'] = data['url'].apply(lambda i: abnormal_url(i))\n","    data['https'] = data['url'].apply(lambda i: httpSecure(i))\n","    data['digits']= data['url'].apply(lambda i: digit_count(i))\n","    data['letters']= data['url'].apply(lambda i: letter_counter(i))\n","    data['Shortining_Service'] = data['url'].apply(lambda x: Shortining_Service(x))\n","    data['having_ip_address'] = data['url'].apply(lambda i: having_ip_address(i))\n","    data = data.drop(['url','domain'],axis=1)\n","    return data.iloc[:, :22]\n","\n","def url_phishing_predictor_jl(link, dt, rf, et):\n","    features = feature_to_input(link)\n","    if (dt.predict(features) + rf.predict(features) + et.predict(features) >= 2):\n","        return 1\n","    return 0"],"metadata":{"id":"3jTQ9F6v0RbV","executionInfo":{"status":"ok","timestamp":1664718661904,"user_tz":-480,"elapsed":951,"user":{"displayName":"JS Chong","userId":"17987847510974043506"}}},"execution_count":135,"outputs":[]},{"cell_type":"markdown","source":["## Wee Din"],"metadata":{"id":"gdlz_4HgEoqI"}},{"cell_type":"code","source":["import csv\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from urllib.parse import urlparse\n","from nltk.tokenize import RegexpTokenizer\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n","from sklearn.preprocessing import FunctionTransformer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.ensemble import RandomForestClassifier,BaggingClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.pipeline import FeatureUnion, Pipeline\n","from sklearn.model_selection import train_test_split\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn import svm\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.svm import LinearSVC\n","\n","class Converter(BaseEstimator, TransformerMixin):\n","    def fit(self, x, y=None):\n","        return self\n","\n","    def transform(self, data_frame):\n","        return data_frame.values.ravel()\n","\n","numeric_features = ['length', 'domain_hyphens', 'domain_underscores', 'path_hyphens', 'path_underscores', 'slashes', 'full_stops', 'num_subdomains']\n","numeric_transformer = Pipeline(steps=[\n","    ('scaler', MinMaxScaler())])\n","\n","categorical_features = ['tld', 'is_ip']\n","categorical_transformer = Pipeline(steps=[\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n","\n","vectorizer_features = ['domain_tokens','path_tokens']\n","vectorizer_transformer = Pipeline(steps=[\n","    ('con', Converter()),\n","    ('tf', TfidfVectorizer())])\n","\n","vectorizer_features = ['domain_tokens','path_tokens']\n","vectorizer_transformer = Pipeline(steps=[\n","    ('con', Converter()),\n","    ('tf', TfidfVectorizer())])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, numeric_features),\n","        ('cat', categorical_transformer, categorical_features),\n","        ('domvec', vectorizer_transformer, ['domain_tokens']),\n","        ('pathvec', vectorizer_transformer, ['path_tokens'])\n","    ])\n","\n","svc_clf = Pipeline(steps=[('preprocessor', preprocessor),\n","                      ('classifier', LinearSVC())])\n","\n","log_clf = Pipeline(steps=[('preprocessor', preprocessor),\n","                      ('classifier', LogisticRegression())])\n","\n","nb_clf = Pipeline(steps=[('preprocessor', preprocessor),\n","                      ('classifier', MultinomialNB())])\n","\n","\n","tokenizer = RegexpTokenizer(r'[A-Za-z]+')\n","def tokenize_domain(netloc: str) -> str:\n","    split_domain = tldextract.extract(netloc)\n","    no_tld = str(split_domain.subdomain +'.'+ split_domain.domain)\n","    return \" \".join(map(str,tokenizer.tokenize(no_tld)))\n","\n","def get_num_subdomains(netloc: str) -> int:\n","    subdomain = tldextract.extract(netloc).subdomain \n","    if subdomain == \"\":\n","        return 0\n","    return subdomain.count('.') + 1\n","\n","def parse_url(url: str): #Optional[Dict[str, str]] --> Saw this online, but not too sure what this is\n","    try:\n","        no_scheme = not url.startswith('https://') and not url.startswith('http://')\n","        if no_scheme:\n","            parsed_url = urlparse(f\"http://{url}\")\n","            return {\n","                \"scheme\": None, #No established value for this --> Think this is for http or https\n","                \"netloc\": parsed_url.netloc,\n","                \"path\": parsed_url.path,\n","                \"params\": parsed_url.params,\n","                \"query\": parsed_url.query,\n","                \"fragment\": parsed_url.fragment,\n","            }\n","        else:\n","            parsed_url = urlparse(url)\n","            return {\n","                \"scheme\": parsed_url.scheme,\n","                \"netloc\": parsed_url.netloc,\n","                \"path\": parsed_url.path,\n","                \"params\": parsed_url.params,\n","                \"query\": parsed_url.query,\n","                \"fragment\": parsed_url.fragment,\n","            }\n","    except:\n","        return None\n","\n","def feature_as_input(link):\n","    link_df = {'url': [link]}\n","    df_grp = pd.DataFrame(link_df)        \n","    df_grp[\"parsed_url\"] = df_grp.url.apply(parse_url)\n","    df_grp = pd.concat([\n","        df_grp.drop(['parsed_url'], axis=1),\n","        df_grp['parsed_url'].apply(pd.Series)\n","    ], axis=1)\n","    df_grp = df_grp[~df_grp.netloc.isnull()]\n","    df_grp[\"length\"] = df_grp.url.str.len()\n","    df_grp[\"tld\"] = df_grp.netloc.apply(lambda nl: tldextract.extract(nl).suffix)\n","    df_grp['tld'] = df_grp['tld'].replace('','None')\n","    df_grp[\"is_ip\"] = df_grp.netloc.str.fullmatch(r\"\\d+\\.\\d+\\.\\d+\\.\\d+\")\n","    df_grp['domain_hyphens'] = df_grp.netloc.str.count('-')\n","    df_grp['domain_underscores'] = df_grp.netloc.str.count('_')\n","    df_grp['path_hyphens'] = df_grp.path.str.count('-')\n","    df_grp['path_underscores'] = df_grp.path.str.count('_')\n","    df_grp['slashes'] = df_grp.path.str.count('/')\n","    df_grp['full_stops'] = df_grp.path.str.count('.')\n","    df_grp['num_subdomains'] = df_grp['netloc'].apply(lambda net: get_num_subdomains(net))        \n","    df_grp['domain_tokens'] = df_grp['netloc'].apply(lambda net: tokenize_domain(net))\n","    df_grp['path_tokens'] = df_grp['path'].apply(lambda path: \" \".join(map(str,tokenizer.tokenize(path))))\n","\n","    df_grp.drop('url', axis=1, inplace=True)\n","    df_grp.drop('scheme', axis=1, inplace=True)\n","    df_grp.drop('netloc', axis=1, inplace=True)\n","    df_grp.drop('path', axis=1, inplace=True)\n","    df_grp.drop('params', axis=1, inplace=True)\n","    df_grp.drop('query', axis=1, inplace=True)\n","    df_grp.drop('fragment', axis=1, inplace=True)\n","\n","    return df_grp.iloc[:, :12]\n","\n","def url_phishing_predictor_wd(link, lr, svc, nb):\n","    features = feature_as_input(link)\n","    if (int(lr.predict(features)[0]) + int(svc.predict(features)[0]) + int(nb.predict(features)[0]) >= 2):\n","        return 1\n","    return 0"],"metadata":{"id":"YU8DzDlkEnUd","executionInfo":{"status":"ok","timestamp":1664718255380,"user_tz":-480,"elapsed":3,"user":{"displayName":"JS Chong","userId":"17987847510974043506"}}},"execution_count":127,"outputs":[]},{"cell_type":"markdown","source":["## Hui Xian"],"metadata":{"id":"2WlA7TYbNTDr"}},{"cell_type":"code","source":["# import pandas as pd\n","# import numpy as np\n","# import seaborn as sns\n","# import matplotlib.pyplot as plt\n","# from sklearn.model_selection import train_test_split\n","# from sklearn.metrics import accuracy_score\n","# from sklearn.tree import DecisionTreeClassifier\n","# from sklearn.ensemble import RandomForestClassifier\n","# from sklearn.neural_network import MLPClassifier\n","# from xgboost import XGBClassifier\n","# from sklearn.svm import SVC\n","# import pickle\n","\n","# dataset = pd.read_csv('Datasets/urldata.csv')\n","# dataset = dataset.sample(frac=1).reset_index(drop=True)\n","\n","# y = dataset.Label\n","# X = dataset.iloc[:, 1:-1]\n","# X = X.drop([\"Web_Traffic\"], axis=1)\n","# X_train, X_test, y_train, y_test = \\\n","#  train_test_split(X, y, test_size=0.2, random_state=12)\n","\n","# # XGBoost\n","# xgb = XGBClassifier(learning_rate=0.4, max_depth=7)\n","\n","# xgb.fit(X_train, y_train)\n","\n","# y_test_xgb = xgb.predict(X_test)\n","# y_train_xgb = xgb.predict(X_train)\n","\n","# acc_train_xgb = accuracy_score(y_train, y_train_xgb)\n","# acc_test_xgb = accuracy_score(y_test, y_test_xgb)\n","\n","# joblib.dump(xgb, \"Models/XGBoostClassifierNew\")"],"metadata":{"id":"yVxCOnQNYiVJ","executionInfo":{"status":"ok","timestamp":1664718255380,"user_tz":-480,"elapsed":2,"user":{"displayName":"JS Chong","userId":"17987847510974043506"}}},"execution_count":128,"outputs":[]},{"cell_type":"code","source":["#!pip install whois\n","import pandas as pd\n","from urllib.parse import urlparse,urlencode\n","import ipaddress\n","import re\n","import sys\n","import whois\n","from datetime import datetime\n","import requests\n","\n","# Domain of the URL\n","def getDomain(url):\n","    domain = urlparse(url).netloc\n","    if re.match(r\"^www.\", domain):\n","        ain = domain.replace(\"www.\", \"\")\n","        return domain\n","\n","# Checks for IP address in URL (Have_IP)\n","def havingIP(url):\n","    try:\n","        ipaddress.ip_address(url)\n","        ip = 1\n","    except:\n","        ip = 0\n","    return ip\n","\n","# Checks the presence of @ in URL (Have_At)\n","def haveAtSign(url):\n","    if \"@\" in url:\n","        at = 1\n","    else:\n","        at = 0\n","    return at\n","\n","# Finding the length of URL and categorizing (URL_Length)\n","def getLength(url):\n","    if len(url) < 54:\n","        length = 0\n","    else:\n","        length = 1\n","    return length\n","\n","# Gives number of '/' in URL (URL_Depth)\n","def getDepth(url):\n","    s = urlparse(url).path.split('/')\n","    depth = 0\n","    for j in range(len(s)):\n","        if len(s[j]) != 0:\n","            depth = depth+1\n","    return depth\n","\n","# Checking for redirection '//' in the url (Redirection)\n","def redirection(url):\n","    pos = url.rfind('//')\n","    if pos > 6:\n","        if pos > 7:\n","            return 1\n","        else:\n","            return 0\n","    else:\n","        return 0\n","\n","# Existence of “HTTPS” Token in the Domain Part of the URL (https_Domain)\n","def httpDomain(url):\n","    domain = urlparse(url).netloc\n","    if 'https' in domain:\n","        return 1\n","    else:\n","        return 0\n","\n","#listing shortening services\n","shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n","                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n","                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n","                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n","                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n","                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n","                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n","                      r\"tr\\.im|link\\.zip\\.net\"\n","\n","# Checking for Shortening Services in URL (Tiny_URL)\n","def tinyURL(url):\n","    match = re.search(shortening_services, url)\n","    if match:\n","        return 1\n","    else:\n","        return 0\n","\n","# Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\n","def prefixSuffix(url):\n","    if '-' in urlparse(url).netloc:\n","        return 1\n","    else:\n","        return 0\n","\n","# Survival time of domain: The difference between termination time and creation time (Domain_Age)  \n","def domainAge(domain_name):\n","    creation_date = domain_name.creation_date\n","    expiration_date = domain_name.expiration_date\n","    if (isinstance(creation_date, str) or isinstance(expiration_date, str)):\n","        try:\n","            creation_date = datetime.strptime(creation_date, '%Y-%m-%d')\n","            expiration_date = datetime.strptime(expiration_date, \"%Y-%m-%d\")\n","        except:\n","            return 1\n","    if ((expiration_date is None) or (creation_date is None)):\n","        return 1\n","    elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n","        return 1\n","    else:\n","        ageofdomain = abs((expiration_date - creation_date).days)\n","        if ((ageofdomain/30) < 6):\n","            age = 1\n","        else:\n","            age = 0\n","    return age\n","\n","# End time of domain: The difference between termination time and current time (Domain_End)\n","def domainEnd(domain_name):\n","    expiration_date = domain_name.expiration_date\n","    if isinstance(expiration_date, str):\n","        try:\n","            expiration_date = datetime.strptime(expiration_date, \"%Y-%m-%d\")\n","        except:\n","            return 1\n","    if (expiration_date is None):\n","        return 1\n","    elif (type(expiration_date) is list):\n","        return 1\n","    else:\n","        today = datetime.now()\n","        end = abs((expiration_date - today).days)\n","        if ((end/30) < 6):\n","            end = 0\n","        else:\n","            end = 1\n","    return end\n","\n","# IFrame Redirection (iFrame)\n","def iframe(response):\n","    if response == \"\":\n","        return 1\n","    else:\n","        if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n","            return 0\n","        else:\n","            return 1\n","\n","# Checks the effect of mouse over on status bar (Mouse_Over)\n","def mouseOver(response): \n","    if response == \"\":\n","        return 1\n","    else:\n","        if re.findall(\"<script>.+onmouseover.+</script>\", response.text):\n","            return 1\n","        else:\n","            return 0\n","\n","# Checks the status of the right click attribute (Right_Click)\n","def rightClick(response):\n","    if response == \"\":\n","        return 1\n","    else:\n","        if re.findall(r\"event.button ?== ?2\", response.text):\n","            return 0\n","        else:\n","            return 1\n","\n","# Checks the number of forwardings (Web_Forwards)    \n","def forwarding(response):\n","    if response == \"\":\n","        return 1\n","    else:\n","        if len(response.history) <= 2:\n","            return 0\n","        else:\n","            return 1\n","\n","def featureExtraction(url):\n","\n","    features = []\n","# Address bar based features (10)\n","    features.append(havingIP(url))\n","    features.append(haveAtSign(url))\n","    features.append(getLength(url))\n","    features.append(getDepth(url))\n","    features.append(redirection(url))\n","    features.append(httpDomain(url))\n","    features.append(tinyURL(url))\n","    features.append(prefixSuffix(url))\n","\n","# Domain based features (4)\n","    dns = 0\n","    try:\n","        domain_name = whois.whois(urlparse(url).netloc)\n","    except:\n","        dns = 1\n","\n","    features.append(dns)\n","    features.append(1 if dns == 1 else domainAge(domain_name))\n","    features.append(1 if dns == 1 else domainEnd(domain_name))\n","\n","# HTML & Javascript based features (4)\n","    try:\n","        response = requests.get(url)\n","    except:\n","        response = \"\"\n","    features.append(iframe(response))\n","    features.append(mouseOver(response))\n","    features.append(rightClick(response))\n","    features.append(forwarding(response))\n","\n","    return features\n","\n","# converting the list to dataframe\n","def get_feature(link):\n","    feature_names = ['Have_IP', 'Have_At', 'URL_Length', 'URL_Depth', 'Redirection', 'https_Domain', 'TinyURL', 'Prefix/Suffix', 'DNS_Record', 'Domain_Age', 'Domain_End', 'iFrame', 'Mouse_Over', 'Right_Click', 'Web_Forwards']\n","    features_hx = pd.DataFrame([featureExtraction(link)], columns=feature_names)\n","    return features_hx.iloc[:, :15]\n","\n","def url_phishing_predictor_hx(link, xgb):\n","    features_hx = get_feature(link)\n","    return xgb.predict(features_hx)[0]\n"],"metadata":{"id":"gFmLGS7nNR_i","executionInfo":{"status":"ok","timestamp":1664718255380,"user_tz":-480,"elapsed":2,"user":{"displayName":"JS Chong","userId":"17987847510974043506"}}},"execution_count":129,"outputs":[]},{"cell_type":"markdown","source":["# Application (Loading Models to Test on Individual URLs)"],"metadata":{"id":"wcvhtyrtBVkf"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/My Drive/DLW Hackathon'\n","#Feel free to change to your path to this folder"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sRnKkH6oKqil","executionInfo":{"status":"ok","timestamp":1664718265957,"user_tz":-480,"elapsed":4809,"user":{"displayName":"JS Chong","userId":"17987847510974043506"}},"outputId":"36559b0c-6c17-4fa9-a80d-4140a05b9c1c"},"execution_count":130,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/DLW Hackathon\n"]}]},{"cell_type":"markdown","source":["Load Models"],"metadata":{"id":"9wKtPQAHAteI"}},{"cell_type":"code","source":["!pip install --no-cache-dir joblib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2p1P9S-AWON","executionInfo":{"status":"ok","timestamp":1664703003835,"user_tz":-480,"elapsed":4263,"user":{"displayName":"JS Chong","userId":"17987847510974043506"}},"outputId":"54000c80-b203-4895-9afc-b7d9121b4313"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.2.0)\n"]}]},{"cell_type":"code","source":["# from fe_js import url_phishing_predictor_js\n","# from fe_wd import url_phishing_predictor_wd\n","# from fe_jl import url_phishing_predictor_jl\n","# from fe_hx import url_phishing_predictor_hx\n","from keras.models import load_model\n","import joblib\n","\n","dir = \"Models/\"\n","\n","#JS\n","rf_imported_js = joblib.load(dir+\"RandomForest\")\n","lg_imported_js = joblib.load(dir+\"LogisticRegression\")\n","xgb_imported_js = joblib.load(dir+\"XGBoost\")\n","nn_imported_js = load_model(dir+\"NeuralNet.h5\")\n","pre_processor_imported_js = joblib.load(dir+\"Preprocessor\")\n","\n","#JL\n","DT_imported_jl = joblib.load(dir+\"DT\")\n","RF_imported_jl = joblib.load(dir+\"RF\")\n","ET_imported_jl = joblib.load(dir+\"ET\")\n","\n","#WD\n","LR_imported_wd = joblib.load(dir+\"LR_WD\")\n","SVC_imported_wd = joblib.load(dir+\"SVC_WD\")\n","NB_imported_wd = joblib.load(dir+\"NB_WD\")\n","\n","#HX\n","XGB_imported_hx = joblib.load(dir+\"XGBoostClassifierNew\")"],"metadata":{"id":"STj_oRShComm","executionInfo":{"status":"ok","timestamp":1664724617851,"user_tz":-480,"elapsed":11814,"user":{"displayName":"JS Chong","userId":"17987847510974043506"}}},"execution_count":146,"outputs":[]},{"cell_type":"code","source":["links_list = []\n","with open(\"Datasets/ALL-phishing-links.txt\") as file:\n","    for line in file:\n","        links_list.append(line.rstrip())\n","\n","print(links_list[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxLTIVAACSl1","executionInfo":{"status":"ok","timestamp":1664719971462,"user_tz":-480,"elapsed":480,"user":{"displayName":"JS Chong","userId":"17987847510974043506"}},"outputId":"896c23a6-8e82-4fd6-c61e-a4a16538961b"},"execution_count":140,"outputs":[{"output_type":"stream","name":"stdout","text":["['ftp://188.128.111.33/IPTV/TV1324/view.html', 'ftp://188.128.111.33/web/sec.htm', 'ftp://me@createkindlebooks.org:Noobasshole@createkindlebooks.org/index.html', 'http://00000000000000000000000000000000000000000.xyz', 'http://00000000000000000000000000000000000000dfjjjhv.000webhostapp.com/Yahoo/YahooAttt/global/attverzon/login.php?.intl=us&.lang=en-US&https://login.yahoo.com/?.src=ym']\n"]}]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","def get_prediction_from_link(link):\n","    jiesheng = url_phishing_predictor_js(link, pre_processor_imported_js, lg_imported_js, xgb_imported_js, rf_imported_js, nn_imported_js)\n","    weedin = url_phishing_predictor_wd(link, LR_imported_wd, SVC_imported_wd, NB_imported_wd)\n","    junlong = url_phishing_predictor_jl(link, DT_imported_jl, RF_imported_jl, ET_imported_jl)\n","    huixian = url_phishing_predictor_hx(link, XGB_imported_hx)\n","    szekee = 0 # Add SK Code here\n","\n","    return jiesheng+junlong+weedin+huixian+szekee\n","\n","dict_res = {0:0, 1:0, 2:0, 3:0, 4:0}\n","for link in links_list[:10]:\n","    print(get_prediction_from_link(link))\n","\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8IRxITw8bU_","executionInfo":{"status":"ok","timestamp":1664724671540,"user_tz":-480,"elapsed":7574,"user":{"displayName":"JS Chong","userId":"17987847510974043506"}},"outputId":"395ad38e-41fc-49c5-8ca8-b393dd3be89a"},"execution_count":149,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","4\n","4\n","4\n","4\n","4\n","3\n","4\n","3\n","4\n"]}]},{"cell_type":"code","source":["try:\n","    link = take_photo(show=1)\n","    if url_phishing_predictor(link, pre_processor_imported_js, lg_imported_js, xgb_imported_js, rf_imported_js, nn_imported_js):\n","        print(\"This is a Phishing Link! Do not click!\")\n","    else:\n","        print(\"This link is safe. Feel free to enter.\")\n","\n","except Exception as err:\n","    # Errors will be thrown if the user does not have a webcam or if they do not\n","    # grant the page permission to access it.\n","    print(str(err))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"at_ExPpxM-od","executionInfo":{"status":"error","timestamp":1664699945183,"user_tz":-480,"elapsed":173283,"user":{"displayName":"JS Chong","userId":"17987847510974043506"}},"outputId":"ef872931-9250-41ab-f23e-e9d42b5a614e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        async function takePhoto(quality) {\n","        const div = document.createElement('div');\n","        const capture = document.createElement('button');\n","        capture.textContent = 'Capture';\n","        div.appendChild(capture);\n","\n","        const video = document.createElement('video');\n","        video.style.display = 'block';\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","        document.body.appendChild(div);\n","        div.appendChild(video);\n","        video.srcObject = stream;\n","        await video.play();\n","\n","        // Resize the output to fit the video element.\n","        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","        // Wait for Capture to be clicked.\n","        await new Promise((resolve) => capture.onclick = resolve);\n","\n","        const canvas = document.createElement('canvas');\n","        canvas.width = video.videoWidth;\n","        canvas.height = video.videoHeight;\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        stream.getVideoTracks()[0].stop();\n","        div.remove();\n","        return canvas.toDataURL('image/jpeg', quality);\n","        }\n","        "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-5f2534f03731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0murl_phishing_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_processor_imported\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlg_imported\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_imported\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_imported\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_imported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This is a Phishing Link! Do not click!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-13af579eed63>\u001b[0m in \u001b[0;36mtake_photo\u001b[0;34m(show, quality)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# get photo data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'takePhoto({})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;31m# get OpenCV format image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjs_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"OCopBzdbMEL_"},"execution_count":null,"outputs":[]}]}